import streamlit as st
import os
import google.generativeai as genai
from dotenv import load_dotenv
from PIL import Image

load_dotenv()

# Configurando a p√°gina
st.set_page_config(
    page_title="roboTICO",
    page_icon="ü§ñ",
    layout="centered",
    initial_sidebar_state="expanded",
)

# CSS
st.markdown(
    """
    <style>
    p {
        text-align: justify;
        text-indent: 32px;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

# Colocando minhas informa√ß√µes no sidebar
st.sidebar.markdown("<h1>Desenvolvido por:</h1>", unsafe_allow_html=True)
st.sidebar.markdown("[Thiago Regueira](https://bento.me/thiagoregueira)")
st.sidebar.subheader("Breve descri√ß√£o do roboTICO:")
st.sidebar.markdown(
    """
    <p>O nome roboTICO √© uma mistura de rob√¥ com o apelido que tenho desde a minha infancia, "TICO", acredito que seja devido ao meu nome, Thiago.</p>
    <p>O projeto √© um chatbot desenvolvido em Python, utilizando a biblioteca Streamlit para a interface do usu√°rio e a API do Google Generative AI para a gera√ß√£o de respostas.</p>
    <p>O arquivo principal do projeto √© o robotico.py, que configura a interface do usu√°rio, carrega uma imagem de avatar para o bot, configura a chave da API do Google Generative AI e inicializa o modelo e o hist√≥rico de bate-papo.</p>
    <p>Al√©m disso, o projeto usa vari√°veis de ambiente para armazenar informa√ß√µes sens√≠veis, como a chave da API do Google, e usa a fun√ß√£o load_dotenv() para carreg√°-la.</p>
    """,
    unsafe_allow_html=True,
)

st.title("roboTICO - Seu TICO e TECO virtual!")

# carregando a foto do bot
chatbot_avatar = Image.open(os.path.join("images", "profile-pic.png"))

# Configurando a chave da API
os.environ["GOOGLE_API_KEY"] = os.getenv("GOOGLE_API_KEY")
genai.configure(api_key=os.environ["GOOGLE_API_KEY"])

# Selecione o modelo
model = genai.GenerativeModel("gemini-pro")

# Inicialize o hist√≥rico de bate-papo
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "Oi! Sou o roboTICO, converse comigo!"}
    ]

# Exibe mensagens de bate-papo do hist√≥rico na reexecu√ß√£o do aplicativo
for message in st.session_state.messages:
    with st.chat_message(
        message["role"],
        avatar=chatbot_avatar if message["role"] == "assistant" else None,
    ):
        st.markdown(message["content"])


def llm_function(query):
    # Verifica se o input do usu√°rio cont√©m um n√∫mero
    if any(char.isdigit() for char in query):
        response_text = "Infelizmente, Ainda n√£o aprendi a mexer com n√∫meros. Favor s√≥ enviar palavras."
    else:
        response = model.generate_content(query)
        response_text = " ".join([part.text for part in response.parts])

    # Exibindo a mensagem do assistente com a foto do bot
    with st.chat_message("assistant", avatar=chatbot_avatar):
        st.markdown(response_text, unsafe_allow_html=True)

    # Armazenando a mensagem do usu√°rio
    st.session_state.messages.append({"role": "user", "content": query})

    # Armazenando a mensagem do usu√°rio
    st.session_state.messages.append({"role": "assistant", "content": response_text})


# Aceita entrada do usu√°rio
query = st.chat_input("Manda!")

# Chamando a fun√ß√£o quando a entrada √© fornecida
if query:
    # Exibindo a mensagem do usu√°rio
    with st.chat_message("user"):
        st.markdown(query)

    llm_function(query)
